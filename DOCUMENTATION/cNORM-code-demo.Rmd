---
title: "cNORM Code Demonstration"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Generating raw-to-norm-score lookup tables with cNORM

#### Overview

This demonstration uses the cNORM package to create publishable norms tables. The demonstration data is from the Tests of Dyslexia (TOD) project (2021). The input file contains data from the TOD-Comprehensive (TOD-C) standardization study, with 1407 cases ranging in age from 6 to 19. The input file includes demographic information and raw scores from three TOD subtests: Irregular Word Spelling (`iws`), Blending (`bln`), and Segmenting (`seg`).

The script proceeds through data preparation, modeling, and output stages. The output includes raw-to-SS lookup tables, in both single-table and tabbed format; a reversal report that flags anomalous age-related changes in standard scores; and a model summary that facilitates replication of the analysis.

To run this demonstration, set up an RStudio project called `cNORM`, with subfolders `CODE`, `INPUT-FILES` and `OUTPUT-FILES`. Save scripts in `CODE`, and run them from within the `cNORM` project.

#### Executable Code

```{r cNORM-demo, eval = FALSE}
suppressMessages(library(cNORM))
suppressMessages(suppressWarnings(library(tidyverse)))
suppressMessages(library(here))
library(writexl)
suppressMessages(library(lubridate))

urlRemote_path  <- "https://raw.github.com/"
github_path <- "wpspublish/DSHerzberg-cNORM/master/INPUT-FILES/"
data_file_name <- "cNORM-demo-TOD-input-data.csv"

input_original <- suppressMessages(read_csv(url(
  str_c(urlRemote_path, github_path, data_file_name)
)))

scores <- c("iws_sum", "bln_sum", "seg_sum")
score_to_norm_stem <- "iws_sum"
score_to_norm_file_name <- str_c(score_to_norm_stem, "-norms-input.csv")
score_to_norm_max_raw <- data.frame(test = score_to_norm_stem) %>%
  mutate(max_raw = case_when(
    str_detect(test, "iws_sum") ~ 44,
    str_detect(test, "bln_sum") ~ 29,
    str_detect(test, "seg_sum") ~ 29
  )) %>%
  pull(max_raw)

age_contin <- input_original %>%
  mutate(across(c(DOB, admin_date),
                ~
                  mdy(.x)),
         age = (DOB %--% admin_date) / years (1)) %>%
  bind_cols(getGroups(.$age)) %>%
  rename(group = ...14) %>%
  select(ID, age, group)

map(
  scores,
  ~
    input_original %>%
    select(ID,!!sym(.x)) %>%
    drop_na(!!sym(.x)) %>%
    left_join(age_contin, by = "ID") %>%
    rename(raw = !!sym(.x)) %>%
    select(ID, age, group, raw)
) %>%
  set_names(scores) %>%
  map2(scores,
       ~
         write_csv(.x,
                   here(
                     str_c("OUTPUT-FILES/", .y, "-norms-input.csv")
                   ))) %>%
  invisible(.)

input <- suppressMessages(read_csv(here(
  str_c("OUTPUT-FILES/", score_to_norm_file_name)
)))

model <- cnorm(
  raw = input$raw,
  group = input$group,
  k = 4,
  terms = 4,
  scale = "IQ"
)

plot(model, "series", end = 8)
checkConsistency(model)

tab_names <- c(
  "6.0-6.3",
  "6.4-6.7",
  "6.8-6.11",
  "7.0-7.3",
  "7.4-7.7",
  "7.8-7.11",
  "8.0-8.5",
  "8.6-8.11",
  "9.0-9.5",
  "9.6-9.11",
  "10.0-10.5",
  "10.6-10.11",
  "11.0-11.5",
  "11.6-11.11",
  "12.0-12.5",
  "12.6-12.11",
  "13.0-13.11",
  "14.0-14.11",
  "15.0-16.11",
  "17.0-18.11"
)

norms_list <- rawTable(
  c(
    6.167,
    6.5,
    6.833,
    7.167,
    7.5,
    7.833,
    8.25,
    8.75,
    9.25,
    9.75,
    10.25,
    10.75,
    11.25,
    11.75,
    12.25,
    12.75,
    13.5,
    14.5,
    16,
    18.0
  ),
  model,
  step = 1,
  minNorm = 40,
  maxNorm = 130,
  minRaw = 1,
  maxRaw = score_to_norm_max_raw,
  pretty = FALSE
) %>%
  set_names(tab_names) %>%
  map(~
        select(.x, raw, norm) %>%
        summarize(raw = raw,
                  ss = round(norm, 0)))

reversal_report <- norms_list %>%
  reduce(left_join,
         by = "raw") %>%
  set_names("raw", tab_names) %>%
  pivot_longer(-raw, names_to = "agestrat", values_to = "ss") %>%
  group_by(raw) %>%
  mutate(reversal = case_when(lag(ss) < ss ~ 1)) %>%
  filter(reversal == 1) %>%
  select(raw, agestrat) %>%
  write_csv(here(
    str_c("OUTPUT-FILES/", score_to_norm_stem, "-reversal-report-age.csv")
  ))

write_xlsx(norms_list,
           here(
             str_c(
               "OUTPUT-FILES/", 
               score_to_norm_stem,
               "-raw-ss-lookup-tabbed-age.xlsx"
             )
           ))

table <- norms_list %>%
  reduce(left_join,
         by = "raw") %>%
  set_names("raw", tab_names)

write_csv(table, 
          here(
  str_c("OUTPUT-FILES/", score_to_norm_stem, "-raw-ss-lookup-table-age.csv")
))

capture.output(
  str_c(score_to_norm_stem, " model summary"), 
  summary(model),
  file = here(
    str_c("OUTPUT-FILES/", score_to_norm_stem, "-model-summ-age.txt")  )
)
```

#### Commented Snippets

##### 1. Data Preparation

Load packages for norming (`cNORM`), data wrangling (`tidyverse`), file path specification (`here`), writing .xlsx output (`writexl`), and working with data/time data (`lubridate`). Specifiy file path tokens. `read_csv()` the input data set into `input_original`, using the `url()` function to retrieve data from a remote website. Use `str_c()` to concatenate the file path tokens into a single file path.

```{r cNORM-demo, echo = 1:14, eval = F}
```

Specify score related tokens. `score_to_norm_max_raw` is a numerical vector containing the maximum possible raw score for `score_to_norm_stem` (the score being normed).

To generate `score_to_norm_max_raw`, start by using `data.frame(test = score_to_norm_stem)` to initialize a single-cell data frame, with the `test` column holding the name of the score to be normed. Use `mutate()` to create a second column (`max_raw`) containing the maximum value for that score.

Use `case_when()` to code `max_raw` conditionally, based on the value of `test`. For example, `str_detect(test, "iws_sum")` returns `TRUE` when the value of `test` contains the string `"iws_sum"`. Under that condition, `case_when()` sets the value of `max_raw` to `44`.

`mutate()` returns a two-column data frame. Use `pull()` to extract the value of `max_raw` into the vector `score_to_norm_max_raw`.

```{r cNORM-demo, echo = 16:24, eval = F}
```

A useful feature of `cNORM` is its capacity to implement optimized age-stratification, constructing age groups that are best suited to the modeling of age-related score changes, based on the characteristics of a particular input data set. Often, *a priori* age groups, which serve the needs of the users of published norms, do not stratify the input sample in the way that best supports the `cNORM` modeling functions. After `cNORM` generates a norming model base on optimized age-stratification, the operator can specify a different age-stratification scheme for the raw-to-norm-score lookup tables. Thus it is possible to recreate the *a priori* age groups in the final output of `cNORM`, in order to support clinical application of the published norms tables.

We invoke `cNORM`'s age-stratification function by calling `cNORM::getGroups()`, which creates a new data frame `age_contin` to hold a continuous age variable (in decimal format) for each case in the input file. We use `mutate(across())` and `lubridate::mdy()` to coerce the date variables (`DOB`, `admin_date`), which are strings in the input file, into a numeric date-time format. Within `mdy()`, the `.x` token represents the variables designated for transformation by `across()`.

Within the same call of `mutate()`, we calculate a new decimal-format `age` variable. The `%--%` operator of `lubridate` creates an arithmetic date-time interval, or duration, between a start date (here `DOB`) and an end date (here `admin_date`). Dividing this interval, which represents chronological age, by a time period (here `years(1)`, which returns 1 year as an arithmetic date-time period), converts chronological age expressed as years-months-days (e.g., 5 years, 6 months, 0 days) in to a decimal-format age value (e.g., 5.5).

By specifying `getGroups(.$age)` we enable `getGroups()` to operate on the `age` column of the current data object.

By default, `getGroups()` attempts to form equal-sized age groups with about 100 cases each. Below are the labels for the 15 age groups that `getGroups()` created from the input sample, which has 1407 cases. Each label is the arithmetic mean of the `age` variable for the cases assigned to that group.

    6.964081  
    8.016325  
    8.612022  
    9.113898  
    9.694660 
    10.378862 
    11.024620
    11.689430 
    12.409892 
    13.102322 
    13.851553 
    14.827028 
    15.693530 
    16.688863
    17.971970

Wrapping `getGroups()` in `bind_cols()` adds a new column to the input data object. This new column, which is provisionally named `...14` for its position in the current data object, contains the age-group assignment for each case in the input sample. We complete the setup of the `age_contin` data frame by renaming `...14` to the more meaningful `group`, and keeping only required columns with `select()`.

```{r cNORM-demo, echo = 26:34, eval = F}
```

The `cNORM` modeling functions operate on one raw score at a time. For tests with multiple subtest scores, the workflow is to feed one score at a time through the `cNORM` functions. The next code block partitions the example data file, which contains three subtest raw scores for each case, into separate data frames for each score. These data frames contain only the variables needed by `cNORM`.

The code includes two iterative segments. In the first, `map()` is used to apply a series of functions to each element of the `scores` vector, which contains the names of the three subtest scores in the input data set. Within `map`, `.x` represents the currently-iterated element of the `scores` vector (i.e., the name of a subtest score).

In the function pipeline, `input_original` is sent to `select` to subset only the columns required by `cNORM`, which are the case `ID` and the subtest score to be normed. Because the vector `scores` contains quoted strings, and `select()` expects unquoted column names, `!!sym(.x)` is used to unquote the currently iterated subtest name. This same unquoting function is used elsewhere in this pipeline.

`drop_na()` deletes rows (cases) that are missing the subtest score currently being normed. `left_join()` joins the columns of the current object with those of the previously created `age_contin`, matching cases `by = "ID"`. To obtain the column configuration required by `cNORM`, `rename()` changes the subtest score name to the generic `raw`, and `select(ID, age, group, raw)` subsets the columns in the preferred left-right sequence.

At this point, `map()` finishes iterating and returns a list of unnamed data frames, one for each subtest score, containing the variables required by `cNORM`. `set_names(scores)` is used to name each data frame with its corresponding subtest label.

Next, the list of data frames is piped into `map2()`, which enables simultaneous parallel iteration over two inputs of equal length (tokenized as `.x` and `.y`). In this call of `map2()`, the current piped object (the list of data frames) is the `.x` input, and the `scores` vector is the `.y` input. Both inputs have three elements (i.e., they are of equal length).

The purpose of the `map2()` call is to write each of the data frames on the input list to an external `.csv` file, where it can then be read back in for processing by `cNORM`. `write_csv()` is used to write the currently iterated `.x` data frame to a file path/file name that includes that currently iterated `.y` subtest score name. `here()` anchors the file path in the `cNORM` project folder, and `str_c()` concatenates three string elements, including the `.y` name, into a new string that is the file path.

Because the script writes external files, there's no need to preserve the list of subtest specific data frames in the global environment. The last function in the pipeline, `invisible()`, ensures that the list object neither prints to the console nor appears in the global environment.

```{r cNORM-demo, echo = 35:53, eval = F}
```

The next code block executes the `cNORM` modeling process, in which age-related development of a latent ability is modeled using raw scores from an normative sample. This model of development is eventually operationalized as a set of raw-to-norm score lookup tables.

As noted previously, `cNORM` operates on one raw score at a time. Here, `read_csv()` is used to read in one of the single-score data frames written out by upstream code. The file path is concatenated from previously initialized tokens. In the present example, `iws_sum` is the raw score to be normed.

`cnorm()` is the modeling function, and its arguments are as follows:

-   `raw`: designates the raw score column in the input data file (here `input$raw`).
-   `group`: designates the age group column in the input data file (here `input$group`).
-   `k`: a power constant that sets the limit on the expansion of the Taylor polynomial series, which controls the precision of estimation of the normative curve. The default value is 4, and values of 3 and 5 can used in searching for an acceptable model. `k = 5` is computationally intensive and entails processing times of 5 to 10 minutes on many CPUs.
-   `terms`: sets the number of terms in the regression equation that expresses the normative model. `cnorm()` finds the best-fitting model with this number of terms. By convention, we use a starting value of 4 for `terms`.
-   `scale`: sets the metric of the norm score. Values can be `"IQ"`,`"T"`,`"z"`, `"percentile"`, or a vector that provides the mean and standard deviation of the preferred metric (e.g., `c(10, 3)`).

```{r cNORM-demo, echo = 54:64, eval = F}
```

The initial output of `cNORM()` is a model summary printed in the console, and a plot of the observed and predicted percentile curves associated with the norming model. The plot shown below is for the `iws` raw score in the input sample.

At this point, the norming process and workflow extends outside the mere sequential execution of this script. The intital model is evaluated, using diagnostic tools available within `cNORM`. If this initial model is judged acceptable, the output phase of the norms process can proceed. However, if the initial model is problematic, we then re-run the `cnorm()` function wtih different values of `k` and `terms`, and examine these subsquent models with the diagnostic aids, repeating the process until we settle on a model that is acceptable (or, at least, the model with the fewest observable flaws).

*Monotonicity* is the primary criterion by which we evaluate the norming model. In most cases, we expect that when we administer a test of a latent ability that develops through childhood, raw scores will increase monotonically (that is, increase without ever decreasing) with increasing age. It follows that a specific raw score is expected to be associated with progressively lower norm scores as age increases. This occurs because we expect the mean raw score to increase from one age group to the next, and, consequently, an identical raw score moves to a lower rank in the next oldest age group, and so on.

The best way to check monotonicity after running `cNORM()` is to examine the plot of percentile curves associated with the model. In this plot, the x-axis variable is age group, and the y-axis variable is raw score. The plot illustrates seven percentile ranks: 2.5, 10, 25, 50, 75, 90, 97.5. The colored circles represent the actual raw scores associated with these percentiles, per age group, in the input data. The solid lines represent the outcome of the modeling process, whereby the selected regression equation is used to smooth the age-related progression of each percentile rank.

If those curves *do not* intersect (as in the example below), the model is adequate and we can proceed to norming output.

The plot also show the proportion of variance in raw scores that is explained by the regression model (here, R^2^ = 0.9677). This value is often quite large, even in models that lack monotonicity. Rather, what we look for in this plot is that the percentile curves do not intersect over the age range of the test.

Intersecting percentile curves would indicate an unexpected change in the raw to norm-score relationship from one age group to the next.

When the plot shows intersecting percentile curves, however, it indicates that the norming model has produced an unexpected result. That is, for example, the same raw score is associated with a higher norm score in the next oldest age group. This situation is also referred to as a norm-score *reversal*.

Usually, the presence of intersecting percentile curves prompts re-running the `cnorm()` modelling function with different parameters (i.e., different values of `k` and `terms`), in order to find a model that yields the optimal non-intersecting percentile curves.

![](/Users/dherzberg/OneDrive%20-%20Western%20Psychological%20Services/Desktop/R/cNORM/DOCUMENTATION/cNORM-code-demo-plot.png) text

```{r cNORM-demo, echo = 66:67, eval = F}
```
