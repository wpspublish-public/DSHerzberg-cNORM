---
title: "Using cNORM's weighting feature"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Overview

`cNORM`[^1] includes a function for weighting data from
non-demographically representative normative samples. The weighting
function is designed to correct bias in the raw-to-norm-score
relationships that might be introduced by non-representative data.

[^1]: The core documentation for `cNORM` is provided in ***Generating
    raw-to-norm-score lookup tables with cNORM*****.**

This markdown document expands on a demonstration of the weighting
function prepared by the `cNORM` author group. To run the demonstration,
set up an RStudio project called `cNORM`, with subfolders `CODE`,
`INPUT-FILES` and `OUTPUT-FILES`. Save scripts in `CODE`, and run them
from within the `cNORM` project.

For normative data, the script uses the `ppvt` (Peabody Picture
Vocabulary Test) data set, which is included in the `cNORM` package.
Weighting is applied with respect to two demographic variables, each
with two categories (levels): `sex` (`1` = `male`, `2` = `female`) and
`migration` status (`0` = `no`, `1` = `yes`). `cNORM`'s weighting
function requires target percentages for the demographic categories,
which are usually obtained from US Census data.[^2]

[^2]: Ersatz target percentages are use in the current demonstration.

To understand the procedures described below, it's useful to visualize a
two-by-two contingency table, with rows for the values of `sex` and
columns for the values of `migration`. This table has four joint
cross-classification cells, representing the four possible combinations
of the categories of `sex` and `migration`.

We can represent the target percentages for the demographic variables on
the table margins (that is, on the left and upper edges of the table.)
These *marginal percentages*, of course, sum to 100% for each variable.
The cells contain the *joint classification percentages* (also summing
to 100%), which are obtained by multiplying the marginal percentages for
each cell's row and column.

|                    |   Non-migrant (65.0%)   |       Migrant (35.0%)       |
|-------------------:|:-----------------------:|:---------------------------:|
|   **Male (51.0%)** |  Male, Migrant (33.1%)  |  Male, Non-migrant (17.9%)  |
| **Female (49.0%)** | Female, Migrant (31.8%) | Female, Non-migrant (17.2%) |

*Marginal* and *joint* are often used analogously to modify terms such
as *proportion*, *distribution*, and so on. "Marginal" thus refers to
the categories of a single variable, considered independently from all
others, and "joint" refers to the crossing of categories of two or more
variables.

The target percentages are the standard of demographic
representativeness. To compensate for non-representativeness in the
normative sample, `cNORM`uses the target percentages to calculate
weighting multipliers. These weights are applied at the raw-score level
to adjust the parameters of the raw-score distributions within
demographic categories. The intended effect is for the weighted raw
scores to have the same numerical impact on the norming process as would
unweighted raw scores in a demographically representative normative
sample (i.e., one in which the sample percentages match the target
percentages).

`cNORM` determines the weights by means of an iterative mathematical
process called *raking*. Importantly, raking operates only on the
marginal percentages. The underlying equations do not explicitly
incorporate the joint percentages. So, although target joint percentages
are sometimes available in US Census data, they are never used as inputs
for `cNORM`'s weighting function.

#### Executable Code

```{r cNORM-weighting-demo, eval = FALSE}
suppressMessages(library(cNORM))
suppressMessages(suppressWarnings(library(tidyverse)))

norm_data <- ppvt
View(norm_data)

marginals_ppvt <- data.frame(var = c("sex", "sex", "migration", "migration"),
                             level = c(1,2,0,1),
                             prop = c(0.5100, 0.4900, 0.6500, 0.3500))
View(marginals_ppvt)

prop.table(xtabs(~sex, data = norm_data))
prop.table(xtabs(~migration, data = norm_data))
prop.table(xtabs(~sex + migration, data = norm_data))

norm_data <- norm_data %>% 
  mutate(weights = computeWeights(data = norm_data, population.margins = marginals_ppvt))

norm_data_weights <- norm_data %>%
  group_by(sex, migration) %>%
  summarize(weights = unique(weights))
View(norm_data_weights)

model_weighted <- cnorm(raw = norm_data$raw,
                       group = norm_data$group,
                       weights = norm_data$weights,
                       scale = "IQ")

model_unweighted <- cnorm(raw = norm_data$raw,
                       group = norm_data$group,
                       scale = "IQ")

age_strat <- c(3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 
                 11.5, 12.5, 13.5, 14.5, 15.5, 16.5)

norms_list_weighted <- rawTable(
  age_strat,
  model_weighted,
  step = 1,
  minNorm = 40,
  maxNorm = 130,
  minRaw = 7,
  maxRaw = 221,
  pretty = FALSE
) %>%
  map(~
        select(.x, raw, norm) %>%
        summarize(raw = raw,
                  ss = round(norm, 0)))

table_weighted <- norms_list_weighted %>%
  reduce(left_join,
         by = "raw") %>%
  set_names("raw", age_strat)

norms_list_unweighted <- rawTable(
  age_strat,
  model_unweighted,
  step = 1,
  minNorm = 40,
  maxNorm = 130,
  minRaw = 7,
  maxRaw = 221,
  pretty = FALSE
) %>%
  map(~
        select(.x, raw, norm) %>%
        summarize(raw = raw,
                  ss = round(norm, 0)))

table_unweighted <- norms_list_unweighted %>%
  reduce(left_join,
         by = "raw") %>%
  set_names("raw", age_strat)

comp_w_uw <-full_join(
  table_weighted,
  table_unweighted,
  by = "raw"
) %>% 
  select(-raw)

chi_square <- map_dbl(seq_len(nrow(comp_w_uw)),
                ~
                  chisq.test(matrix(as.numeric(comp_w_uw[.x, 1:ncol(comp_w_uw)]), nrow = 2, ncol(comp_w_uw)/2, 2))$statistic)
comp_w_uw$chi_square <- chi_square

chi_sq_max <- max(comp_w_uw$chi_square)
df <- length(age_strat) - 1
chi_sq_crit <- qchisq(.05, df)
if_else(chi_sq_max < chi_sq_crit,
        "Weighted, unweighted lookup tables DO NOT DIFFER significantly (per chi-square test).",
        "Weighted, unweighted lookup tables DIFFER significantly (per chi-square test)")

comp_w_uw <- comp_w_uw %>% 
  mutate(effect_size = sqrt(chi_square/(nrow(.) * df)))
effect_size_max <- max(comp_w_uw$effect_size)
df_V <- min(length(age_strat), 2) - 1
```

#### Commented Snippets

Load packages for norming (`cNORM`) and data wrangling (`tidyverse`).
Assign the `ppvt` data set to the `norm_data` object. `View()` the data
set to inspect the following columns:

-   `age`: as a decimal value.
-   `sex`, `migration`, `region`: demographic variables (`region` is not
    used in this example).
-   `raw`: PPVT raw score.
-   `group`: age group membership (previously assigned by `cNORM`),
    group labels are mean value of age for all persons in that group.

```{r cNORM-weighting-demo, echo = 1:5, eval = F}
```

`cNORM` requires that the target demographic percentages, or
"marginals", be specified in a multi-level data frame with three
columns:

-   `var`: names of demographic variables in the analysis, each name is
    repeated for the number of categories (levels) in that variable
    (e.g., `sex` has `male` and `female` categories, so it is specified
    twice). `level` and `prop` have values for each category of the
    demographic variables named on `var` (i.e., `level` and `prop` are
    nested within `var`).
-   `level`: numerical coding for categories of `var`.
-   `prop`: target census percentages for categories of `var`, specified
    as decimal proportions.

The columns must be in the left-right sequence shown here. The data
frame is initialized with `data.frame()` and assigned to
`marginals_ppvt`.

![](images/Screen%20Shot%202022-08-18%20at%202.43.24%20PM.png){width="200"}

```{r cNORM-weighting-demo, echo = 7:10, eval = F}
```

The next snippet uses `prop.table(xtabs())` to provide a view (in the
console) of actual percentages of `sex` and `migration` in `norm_data`.
The first two lines process `sex` and `migration` independently. In the
inner parentheses, the variable to be processed is specified with the
formula operator `~`, and the input data object is given in the `data =`
argument. `xtabs()` counts the number of persons in each category of the
named variable, and `prop.table()` converts these counts into decimal
proportions.

The third line processes the cross-tabulation of the two demographic
variables (specified with `~sex + migration`). The values in the
resulting 2 x 2 table are the *joint proportions* for the four
cross-classification cells. For instance, the value in the upper-left
cell is the proportion of persons in the sample who are classified `1`
for `sex`, ***and*** `0` for `migration`.

By contrast, values calculated by the single-variable calls of
`prop.table(xtabs())` are the *marginal proportions* for those
variables, considered independently of one another.

```{r cNORM-weighting-demo, echo = 12:14, eval = F}
```

`computeWeight()` is `cNORM`'s weighting function. Its arguments are the
input data set `data =` and the data frame containing the target census
percentages `population.margins =`.

`computeWeight()` calculates weights for each joint classification cell,
based on the marginal percentages for the demographic variables. It
returns a numerical vector (here assigned to `weights_ppvt`) containing
weights for each person in the normative sample, based on that person's
classification on the demographic variables considered in the weighting
analysis. `computeWeight()` also standardizes the weights, by dividing
each weight by the smallest weight yielded by analysis. This sets the
weight associated with the most over-sampled joint classification cell
to 1. The weights in the current example are:

|            |        Non-migrant        |            Migrant            |
|-----------:|:-------------------------:|:-----------------------------:|
|   **Male** |  Male, Migrant: 1.000000  |  Male, Non-migrant: 1.403915  |
| **Female** | Female, Migrant: 1.007713 | Female, Non-migrant: 1.414743 |

In this snippet, we pipe `norm_data` into `mutate()` to create a new
column `weights`. Within `mutate()`, we execute `computeWeights()`,
populating the new column with the weights for each person in
`norm_data`.

```{r cNORM-weighting-demo, echo = 16:17, eval = F}
```

The script generates a data frame `norm_data_weights` that shows the
weights associated with the four cross-classification cells. In the next
snippet, we group `norm_data` by `sex` and `migration`, which creates a
four-row structure to hold the weights for the cross-classification
cells. We then call `summarize`, which appends a new column `weights` to
the four-row summary table. `unique()` returns only the unique values
from its argument (a vector or column). Here, it fills the `weights`
column with a single correct value for each row.

![](images/Screen%20Shot%202022-08-19%20at%204.10.17%20PM-01.png){width="249"}

```{r cNORM-weighting-demo, echo = 19:23, eval = F}
```

The next code block uses `cnorm()` to execute the normative modeling
process, for both the weighted and original (unweighted) input samples.
Note the use of the argument `weights =` to produce the weighted model.

The code then generates raw-to-norm-score lookup tables for the weighted
and unweighted norm models. The modeling and output table functions of
`cNORM` are documented in detail elsewhere.[^3]

[^3]: See ***Generating raw-to-norm-score lookup tables with
    cNORM*****.**

```{r cNORM-weighting-demo, echo = 24:74, eval = F}
```

The final step of this demonstration is to examine the differences
between the weighted and unweighted output. The next code block is a
method for comparing raw-to-norm-score lookup tables derived from
weighted normative samples to those derived from unweighted samples. The
method[^4] includes both significance testing of the differences between
the tables, and calculation of an effect size measure.

[^4]: The method was developed by Nan Wang of WPS R&D.

The conceptual basis of the significance test is to view the two lookup
tables as analogous to two different samples. Under this framework, the
normative age strata (age groups) represent categories of a nominal
variable, and the norm scores within those categories are analogous to
counts of persons. A chi-square test can be used to compare the two
"samples" (lookup tables), in terms of the distribution of "persons"
(norm score "counts") across the "categories" (age groups). In this
test, the null hypothesis is that there is no difference between the
distributions embodied in the two tables. The alternative hypothesis is
that a difference exists. The degrees of freedom for this chi-square
test is the number of age groups in the lookup tables, minus one (here:
14-1 = 13).

To compare the two tables, we first bind their columns with
`full_join()`, and then drop the `raw` column with `select()`. This
returns a single data frame `comp_w_uw` holding only the weighted and
unweighted standard score columns (one per age group), arranged
side-by-side.

```{r cNORM-weighting-demo, echo = 75:82, eval = F}
```

The next snippet conducts the chi-square test on `comp_w_uw`. It appends
`comp_w_uw` with a new column `chi_square` that contains row-wise
chi-square statistics. To clarify, each row of `comp_w_uw` holds the
standard scores (by age group) corresponding to a single raw score, for
the weighted and unweighted normative data. The chi-square statistic
represents a test of whether the null hypothesis can be rejected.
Rejection of the null means that, for a particular raw score, there is a
statistically significant difference between the weighted and unweighted
tables with respect to the distribution of standard scores.

The analytic approach is to apply `chisq.test()` to each row of
`comp_w_uw`. `chisq.test()` expects a matrix with two rows, each
containing one of the "distributions" to be compared. In `comp_w_uw`,
these two "distributions" are arranged side-by-side in a single row. We
isolate this single row with `comp_w_uw[.x, 1:ncol(comp_w_uw)]`, where
the subsetting brackets `[]` identify, within `comp_w_uw`, a row `.x`,
and the indexes of the required columns `1:ncol(comp_w_uw)`. This
expression returns a data frame row, which is then wrapped in
`as.numeric()` to transform it into a numerical vector. To convert the
vector into the matrix expected by `chisq.test()`, we wrap it in
`matrix()`, specifying that the vector is to be split in half
`ncol(comp_w_uw)/2, 2`, with the two halves stacked on top of each other
as two rows of a matrix `nrow = 2`. `chisq.test()` returns a list, from
which we extract the test statistic with `$statistic`.

The previous paragraph describes the functions necessary to process one
row of `comp_w_uw`. To process all the rows, we apply the functions
iteratively with `map_dbl()`. The first argument of `map_dbl()` is
`seq_len(nrow(comp_w_uw)`, which returns a numerical sequence whose
length is the same as the number of rows in `comp_w_uw`. Thus,
`map_dbl()` iterates over this sequence, passing successive row numbers
to the `.x` token in `comp_w_uw[.x, 1:ncol(comp_w_uw)]`, so that
`chisq.test()` is applied to every row in `comp_w_uw`. `map_dbl()`
returns a numerical vector, (assigned to `chi_square`), which we bind to
`comp_w_uw` as a new column with `comp_w_uw$chi_square <- chi_square`.
That new column now contains the chi-square values associated with the
comparison of the two "distributions" in each row.

```{r cNORM-weighting-demo, echo = 83:87, eval = F}
```

To test for statistical significance, we use the maximum of the obtained
row-wise chi-square values `chi_sq_max` (here 0.311). To look up the
critical value of chi-square, we call `qchisq()`, passing as arguments a
significance level `.05` and the degrees of freedom `df` (the number of "categories", or age groups, minus one).
`qchisq()` returns a critical value of 5.89, which we assign to
`chi_sq_crit`.

We specify the comparison of the obtained chi-square to the critical
value with the predicate `chi_sq_max < chi_sq_crit`. When this predicate returns `TRUE`, we fail to reject the null hypothesis that there is no difference between the weighted and unweighted lookup tables. When `FALSE` is returned, we reject the null and accept the alternative that a statisically significant difference exists between the two tables. We use `if_else()` to print the interpretation of the significance test, passing as arguments the predicate, followed by strings to print, first when the predicate returns `TRUE`,
then when it returns `FALSE`.

In the current example, 0.311 is less than 5.89, so the predicate
returns `TRUE` and
`"Weighted, unweighted lookup tables DO NOT DIFFER significantly (per chi-square test)."`
prints to the console. The chi-square test therefore reveals that we
cannot reject the null hypothesis that there is no difference between
the distributions embodied by the two lookup tables. In other words,
even though the weighted and unweighted raw-to-norm-score look up tables
may may have numerous small pairwise differences between analogous
cells, the overall difference betweeen the distributions of these
pairwise differences does not reach the threshold of statistical
significance, when we apply the chi-square test in the manner described.

```{r cNORM-weighting-demo, echo = 88:93, eval = F}
```

In addition to significance test, we can also calculate effect sizes for
the row-wise chi-square values. Cramer's V provides a useful measure of
chi-square effect size. The formula is:

![](images/Screen%20Shot%202022-08-26%20at%201.41.45%20PM.png){width="156"}

Where *n* is the number of rows in `comp_w_uw`. In the snippet below, we
apply the Cramer's V formula within `mutate()` to obtain a new `effect_size` column
for `comp_w_uw`. The `max()` of `effect_size` is the largest value
across all rows of `comp_w_uw`. Here that maximum value is 0.011.

To interpret this effect size, we can refer to a table provided by Cohen
(1988)[^5]:

[^5]: Cohen, J. (1988). *Statistical power analysis for the behavioral
    sciences* (2nd ed). Hillsdale, N.J: L. Erlbaum Associates.

![](images/Screen%20Shot%202022-08-26%20at%202.31.21%20PM.png){width="420"}

Here, `df` is not the value used for chi-square test, but is in fact
related to the dimensions of the matrix that served as input to that
test. Specifically, `df_V` is the lesser of the number of columns of the
matrix and the number of rows of the matrix, minus one. In our example, the matrix has
14 columns (one for each age group) and two rows (weighted vs.
unweighted data). Thus, `df_V` is 1. Referencing the table, we see that
the effect size is negligible for the largest row-wise chi-square value.

```{r cNORM-weighting-demo, echo = 94:98, eval = F}
```

In the final analysis, therefore, the use of weighting to correct for
norm-score bias in a non-demographically representative normative sample
***did not*** result in practically meaningful adjustments to the raw-to-norm-score relationships, in comparison to the unweighted normative model. This makes intuitive sense: the mere presence of demographic non-representativeness does not necessarily cause a change in the distribution of raw scores of sufficient magnitude that it would affect the output of the norming process. This is especially true with respect to `cNORM`, which uses a regression-based modeling procedure to smooth out age-related irregularities in the raw score distribution. Any effects of demographic non-representativeness may well be captured and corrected by `cNORM`'s foundational mathematics, irrespective of the subsequent influence of the weighting function.
